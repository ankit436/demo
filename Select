WITH RankedData AS (
    SELECT 
        id, project_name, BIONICS_TEAM, TITLE, STATE, PROGRAM, SOLUTION_PATH, 
        DESCRIPTION, BUSINESS_FUNCTION_DETAIL, REGION, BENEFICIARY_CLIENT_COUNT, 
        BUSINESS_EVP, SPONSOR, BU_FUNCTION_LEAD, DELIVERY_MANAGER, BENEFIT_DRIVER, AS_OF_DATE, 
        ROW_NUMBER() OVER (ORDER BY id) AS row_num
    FROM rindata.Benefits_Ado_Data
),
BatchedData AS (
    SELECT *,
           CEIL(row_num / 4.0) AS batch_number  -- 4 is the batch size
    FROM RankedData
)
SELECT batch_number, COUNT(*) AS batch_size, 
       MAX(id) as max_id, MAX(AS_OF_DATE) as max_as_of_date
FROM BatchedData
GROUP BY batch_number
ORDER BY batch_number;


SELECT batch_number, COUNT(*) AS batch_size, 
       MAX(id) as max_id, MAX(as_of_date) as max_as_of_date
FROM (
    SELECT *,
           CEIL(ROW_NUMBER() OVER (ORDER BY id) / 4.0) AS batch_number  -- 4 is the batch size
    FROM rindata.Benefits_Ado_Data
) AS BatchedData
GROUP BY batch_number
ORDER BY batch_number

from multiprocessing import Pool

def process_row(rowproxy):
    d = {}
    for column, value in rowproxy.items():
        d[column] = value
    return d

def process_rows_parallel(rows, num_processes=None):
    with Pool(processes=num_processes) as pool:
        ado_data_list = pool.map(process_row, rows)
    return ado_data_list

# Example usage
rows = ...  # Your SQLAlchemy result set
num_processes = 4  # Set this to the number of processes you want to use
ado_data_list = process_rows_parallel(rows, num_processes)
